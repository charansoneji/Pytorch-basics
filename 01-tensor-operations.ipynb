{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### by Charan Lalchand Soneji\n",
    "\n",
    "Pytorch is an open source library used for ML operations which was created by Facebook.\n",
    "Some of the functions discussed are:\n",
    "- torch.randn()\n",
    "- torch.add()\n",
    "- torch.clamp()\n",
    "- torch.erf()\n",
    "- torch.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - torch.randn()\n",
    "\n",
    "This function is used to generate a tensor of size 'n', which is specified as a parameter in the function. The values obtained have an overall mean of 0 and a variance of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of random tensors generated are: tensor([ 0.0858,  0.0928,  0.1352,  2.0057, -1.1905])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working example of torch.randn()\n",
    "random=torch.randn(5)\n",
    "print(\"List of random tensors generated are: {}\".format(random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in the above example, we have specified a parameter of 5 inside our torch.randn() function which results in 5 randomly generated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of randomly generated tensors is given as:\n",
      " tensor([[-0.0083, -0.6507, -0.4653, -0.1265, -0.8600, -0.9617],\n",
      "        [ 1.8241, -0.2673,  0.4912, -1.8465,  0.3736, -1.1710],\n",
      "        [-1.0676, -0.8678,  0.7998,  0.8005,  0.4656, -0.3603]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "random=torch.randn(3,6)\n",
    "print(\"Matrix of randomly generated tensors is given as:\\n {}\".format(random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the randn() function can also be used in order to generate matrices of tensors which is done in the example. Here, we give in 2 arguments which represent the number of rows and columns of the matrix obtained. Like in the above example, it may be seen that 3 refers to the number of rows and 6 refers to the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randn() received an invalid combination of arguments - got (), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a8abbceefe31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: randn() received an invalid combination of arguments - got (), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "torch.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in the above example, since we havent passed any parameters to the randn() function, it returns an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the given function is used while setting a randomly given set of weights and biases just before the training of any model. Examples may be seen in the case of a linear regression model whereby weights and biases are set using rand() and a random set of matrix tensor is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - torch.add()\n",
    "\n",
    "Used in order to add any 2 tensors within our eniroment. It can be used to perform operations to one tensor or to two tensors as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randonly generated tensor before addition: tensor([-1.3173,  0.4178,  0.4366, -0.6230,  1.0592])\n",
      "Tensor obtained after addition: tensor([18.6827, 20.4178, 20.4366, 19.3769, 21.0592])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working example of torch.add()\n",
    "a=torch.randn(5)\n",
    "print(\"Randonly generated tensor before addition: {}\".format(a))\n",
    "a=torch.add(a,20)\n",
    "print(\"Tensor obtained after addition: {}\".format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the given example, we have generated a random tensor with 5 values and performed scalar addition to it. Whenever a single tensor is passed to the function along with a scalar value, scalar addition to each of the values of the tensor is perfomed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated tensor a: tensor([ 0.6545, -0.9548,  0.4864,  0.8644])\n",
      "Randomly generated tensor b: tensor([[-0.3637],\n",
      "        [-1.5847],\n",
      "        [-0.8539],\n",
      "        [ 0.4287],\n",
      "        [ 1.1599]])\n",
      "On addition of 'a' with scalar multiple of 10 with 'b':\n",
      "tensor([[ -2.9824,  -4.5918,  -3.1505,  -2.7726],\n",
      "        [-15.1927, -16.8020, -15.3607, -14.9828],\n",
      "        [ -7.8848,  -9.4941,  -8.0529,  -7.6749],\n",
      "        [  4.9414,   3.3320,   4.7733,   5.1512],\n",
      "        [ 12.2533,  10.6439,  12.0852,  12.4631]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "a=torch.randn(4)\n",
    "print(\"Randomly generated tensor a: {}\".format(a))\n",
    "b=torch.randn(5,1)\n",
    "print(\"Randomly generated tensor b: {}\".format(b))\n",
    "print(\"On addition of 'a' with scalar multiple of 10 with 'b':\\n{}\".format(torch.add(a,b,alpha=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have declared a 1 dimension tensor as a and a 2 dimension tensor as b which is then multiplied using scalar multiplication with 'alpha' which is a given parameter of torch.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-12304b926dd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "a=torch.randn(4)\n",
    "b=torch.randn(5,3)\n",
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, since the size of the two tensors is not the same, they cannot be simply added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever the weights or bias have to be altered after a specific iteration or epoch in a enviroment, they can be done with the help of this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - torch.clamp()\n",
    "\n",
    "It basically ensures that all the values in the tensor are within a given specific range and does nto exceed that. For the values that do go beyond range, they are modified to the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated tensor 'a': tensor([ 0.3519, -1.1533,  0.9021,  0.2696,  0.3591])\n",
      "Values after clamping are: tensor([0.3519, 0.2000, 0.5000, 0.2696, 0.3591])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working exmaple of torch.clamp()\n",
    "a=torch.randn(5)\n",
    "print(\"Randomly generated tensor 'a': {}\".format(a))\n",
    "print(\"Values after clamping are: {}\".format(torch.clamp(a,min=.2,max=.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to ensure that the values are between 0.2 and 0.5 and the following parameters have been given to the torch.clamp() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated tensor 'a': tensor([ 0.0317,  1.4063,  0.1407, -0.3402,  1.4409])\n",
      "Values after clamping are: tensor([ 0.0317,  0.5000,  0.1407, -0.3402,  0.5000])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "a=torch.randn(5)\n",
    "print(\"Randomly generated tensor 'a': {}\".format(a))\n",
    "print(\"Values after clamping are: {}\".format(torch.clamp(a,max=.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only mentioning the upper limit of 0.5, it clamps all the values greater than 0.5 to be 0.5 and does not affect the lower values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of 'min' or 'max' must not be None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5fd3add5cbba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of 'min' or 'max' must not be None"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "a=torch.randn(5)\n",
    "torch.clamp(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the attributes of min and max are not specified, it is not known about the parameters to which the tensor is to be clamped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever the values are required to be within a given range, the clamp function is to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - torch.erf()\n",
    "\n",
    "It provides the error functions of each of the the tensor values.\n",
    "It is an inbuilt module of torch which saves us time by easing the calculation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated tensor:\n",
      "tensor([ 0.4616, -0.8944, -1.6780, -0.7144,  1.1185])\n",
      "The error function of each of the values is given by the following resultant tensor:\n",
      " tensor([ 0.4862, -0.7941, -0.9824, -0.6876,  0.8863])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working example of torch.erf()\n",
    "a=torch.randn(5)\n",
    "print(\"Randomly generated tensor:\\n{}\".format(a))\n",
    "print(\"The error function of each of the values is given by the following resultant tensor:\\n {}\".format(torch.erf(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error function is given by a fixed formula and the torch.erf() contains of a single argument which is the tensor itself and it outputs the tensor whereby each value represents the error value calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated tensor:\n",
      "tensor([-0.3974, -1.8043,  2.7671, -1.3477, -0.0359])\n",
      "The 'inverse error function' of each of the values is given by the following resultant tensor:\n",
      " tensor([-0.3682,     nan,     nan,     nan, -0.0318])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "a=torch.randn(5)\n",
    "print(\"Randomly generated tensor:\\n{}\".format(a))\n",
    "print(\"The 'inverse error function' of each of the values is given by the following resultant tensor:\\n {}\".format(torch.erfinv(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we have calculated the Inverse error function using the formula which returns a value of (-infinity) which is not displayabel hence the output given is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "erf() missing 1 required positional arguments: \"input\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-45700e9707c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: erf() missing 1 required positional arguments: \"input\""
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "a=torch.randn(5)\n",
    "torch.erf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the parameter or argument of the tensor is not passed in order to evaluate the error function, an error is thrown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be used to calculate the error function during evaluation of our model but in most cases, the error function from the module Torch.nn is preferred or our own error function can be made use of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - torch.stack()\n",
    "\n",
    "According to the documentation, it concatenates sequence of tensors along a new dimension as long as these tensors are of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random generated tensor a: tensor([[ 0.9872, -1.0135, -1.3007],\n",
      "        [-0.3488, -0.0740,  0.3266]])\n",
      "Random generated tensor b: tensor([[ 0.4768,  2.2769, -0.4442],\n",
      "        [-0.6516,  0.3097,  0.7242]])\n",
      "Random generated tensor c: tensor([[ 1.1128, -1.2929, -1.2215],\n",
      "        [-0.8428, -0.2639,  0.3746]])\n",
      "The stack obtained from tensors are: \n",
      "torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "a=torch.randn(2,3)\n",
    "print(\"Random generated tensor a: {}\".format(a))\n",
    "b=torch.randn(2,3)\n",
    "print(\"Random generated tensor b: {}\".format(b))\n",
    "c=torch.randn(2,3)\n",
    "print(\"Random generated tensor c: {}\".format(c))\n",
    "print(\"The stack obtained from tensors are: \\n{}\".format(torch.stack([a,b,c]).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the stack size represents a tuple with 3 arguments: (a,b,c) where a represents the number of tensors, b represents the number of rows and c represents the number of columns. It is to be noted that b and c have to have the same value in order to make use of the stack function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked tensors are shown by:\n",
      "tensor([[[ 0.8187, -0.4476,  1.0783],\n",
      "         [-0.0620, -0.3029,  0.3287],\n",
      "         [-0.4454,  2.2939,  0.6369]],\n",
      "\n",
      "        [[-0.1665, -0.7349,  0.3001],\n",
      "         [ 0.6647,  3.3316,  1.9687],\n",
      "         [-0.9410,  0.5416,  0.1764]]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "a=torch.randn(3,3)\n",
    "b=torch.randn(3,3)\n",
    "print(\"Stacked tensors are shown by:\\n{}\".format(torch.stack([a,b])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the stacks are represented of the two randomly generated tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [4, 5] at entry 0 and [3, 7] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-702e53436a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Stacked tensors are shown by:\\n{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [4, 5] at entry 0 and [3, 7] at entry 1"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "a=torch.randn(4,5)\n",
    "b=torch.randn(3,7)\n",
    "print(\"Stacked tensors are shown by:\\n{}\".format(torch.stack([a,b])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the tensors are of different dimension, hence while trying to combine them into a single stack tensor, we obtain an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiple epochs are to be carried out and the weights or bias'es are to be kept track of, a stack can be used which will keep appending the values of the weight or bias and would not throw an error since its dimension remains constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have discussed a number of functions which we would commonly as we work with models and training throughout. Some of the main functions include, add(), stack(), randn(), clamp() and erf(). Once we have fammiliarized ourselves with these algos, we can move to working with understanding of ML based algorithms and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* This is something i read of `erf and erfinv`: https://discuss.pytorch.org/t/erf-and-erfinv-functions-in-pytorch/1313/6\n",
    "* Din't find the documentation of `stacks` to be explanatory hence I used this: https://stackoverflow.com/questions/52288635/how-to-use-torch-stack-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\n",
      "[jovian] Updating notebook \"charan-soneji-cls/01-tensor-operations-ba06f\" on https://jovian.ml/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Committed successfully! https://jovian.ml/charan-soneji-cls/01-tensor-operations-ba06f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/charan-soneji-cls/01-tensor-operations-ba06f'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
